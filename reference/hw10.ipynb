{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T06:54:48.508891Z",
     "start_time": "2020-06-07T06:54:48.247497Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: unrecognized arguments: Jeong-Hyeon'\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Moon Jeong-Hyeon' -u -d -p numpy,pandas,matplotlib,sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** 코딩해야할 부분을 제외하고는 수정하지 마세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, ssl\n",
    "# if (not os.environ.get('PYTHONHTTPSVERIFY', '') and\n",
    "#     getattr(ssl, '_create_unverified_context', None)): \n",
    "#     ssl._create_default_https_context = ssl._create_unverified_context  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T06:55:03.109724Z",
     "start_time": "2020-06-07T06:54:49.615474Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist_sci = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T06:55:03.494027Z",
     "start_time": "2020-06-07T06:55:03.117550Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train_, y_test_ = train_test_split(mnist_sci.data, mnist_sci.target, \n",
    "                                                    test_size = 0.1,\n",
    "                                                   shuffle = True)\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n",
    "x_train = x_train.reshape(-1,1,28,28)\n",
    "x_test = x_test.reshape(-1,1,28,28)\n",
    "\n",
    "def one_hoy_label(X):\n",
    "    T = np.zeros((X.size, 10))    \n",
    "    for idx, row in enumerate(T):\n",
    "        row[int(X[idx])] = 1\n",
    "        \n",
    "    return T\n",
    "\n",
    "y_train = one_hoy_label(y_train_)\n",
    "y_test = one_hoy_label(y_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax_CE:\n",
    "    \"\"\"\n",
    "    편의를 위해서 softmax와 crossenropy를 결합한 것입니다.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.loss = None # 손실함수\n",
    "        self.y = None    # softmax의 출력\n",
    "        self.t = None    # 정답 레이블(원-핫 인코딩 형태)\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = CE_loss(self.y, self.t)\n",
    "        \n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 1 에서 구현한 것을 바탕으로 CNN도 적용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x = x.T\n",
    "    x = x-np.max(x, axis=0)\n",
    "    y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "    return y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CE_loss(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "    \n",
    "    batch_size = y.shape[0]\n",
    "    ce = -np.sum(t*np.log(y))\n",
    "    ce /= batch_size\n",
    "    return ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mask = (x<=0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FClayer:\n",
    "    def __init__(self, W, b):\n",
    "        \n",
    "        self.W = W\n",
    "        self.b = b \n",
    "        self.x = None\n",
    "\n",
    "        self.original_x_shape = None\n",
    "        \n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.original_x_shape = x.shape\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        self.x = x\n",
    "\n",
    "        out = np.dot(self.x, self.W) + self.b\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        dx = dx.reshape(*self.original_x_shape)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW10 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = x_train[0:100]\n",
    "b1 = 0.01 * np.random.randn(3, 1, 3, 3)\n",
    "c1 = np.zeros(3)\n",
    "\n",
    "b2 = 0.01 * np.random.randn(int(3 * (26/2) * (26/2)), 16)\n",
    "c2 = np.zeros(16)\n",
    "\n",
    "b3 = 0.01 * np.random.randn(16, 10)\n",
    "c3 = np.zeros(10)\n",
    "\n",
    "# network = SimpleConvNet(input_dim=(1,28,28), \n",
    "#                         conv_param = {'filter_num': 3, 'filter_size': 3, 'pad': 0, 'stride': 1},\n",
    "#                         hidden_size=16, output_size=10)s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv_layer = Conv(b1, c1, stride = 1 , pad = 0)\n",
    "out = conv_layer.forward(a)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Relu()\n",
    "out = r.forward(out)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = MaxPooling(pool_h = 2, pool_w = 2, stride = 2)\n",
    "out = m.forward(out)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fc1_layer = FClayer(b2, c2)\n",
    "fc_out = fc1_layer.forward(out)\n",
    "fc_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = Relu()\n",
    "relu2_out = r2.forward(fc_out)\n",
    "\n",
    "fc2_layer = FClayer(b3, c3)\n",
    "fc2_out = fc2_layer.forward(relu2_out)\n",
    "\n",
    "sce = Softmax_CE()\n",
    "loss = sce.forward(fc2_out, y_train[:100])\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dout = sce.backward(1)\n",
    "dout = fc2_layer.backward(dout)\n",
    "dout = r2.backward(dout)\n",
    "dout = fc1_layer.backward(dout)\n",
    "dout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dout_pooling = m.backward(dout)\n",
    "dout_relu1 = r.backward(dout_pooling)\n",
    "dout_relu1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dout_conv = conv_layer.backward(dout_relu1)\n",
    "dout_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = {}\n",
    "grads['W1'], grads['b1'] = b1, c1\n",
    "grads['W2'], grads['b2'] = b2, c2\n",
    "grads['W3'], grads['b3'] = b3, c3\n",
    "\n",
    "new_grads = {}\n",
    "new_grads['W1'], new_grads['b1'] = conv_layer.dW, conv_layer.db\n",
    "new_grads['W2'], new_grads['b2'] = fc1_layer.dW, fc1_layer.db\n",
    "new_grads['W3'], new_grads['b3'] = fc2_layer.dW, fc2_layer.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv():\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        self.x = None   \n",
    "        \n",
    "        # 가중치와 편향 매개변수의 기울기\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "        \n",
    "        self.out_h = None\n",
    "        self.out_w = None\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # backward 의 shape 확인을 위해서 저장\n",
    "        self.x = x[:]        \n",
    "        \n",
    "        FN, C_, FH, FW = self.W.shape\n",
    "        N, C, H, W = x.shape\n",
    "        \n",
    "        # output 출력 shape \n",
    "        self.out_h = 1 + int((H + 2*self.pad - FH) / self.stride)\n",
    "        self.out_w = 1 + int((W + 2*self.pad - FW) / self.stride)\n",
    "        out_h = self.out_h\n",
    "        out_w = self.out_w        \n",
    "        \n",
    "        # padding\n",
    "        pad_x = np.pad(\n",
    "            x, \n",
    "            ((0, 0), (0, 0), (self.pad, self.pad), (self.pad, self.pad)), \n",
    "            \"constant\", constant_values=0\n",
    "        )        \n",
    "        out = np.zeros((N, FN, out_h, out_w))        \n",
    "        for n in range(N):\n",
    "            for f in range(FN):\n",
    "                for j in range(out_h):\n",
    "                    for i in range(out_w):\n",
    "                        ######################################################################\n",
    "                        # 문제 2-1-1 forward를 구현 하세요                                   #\n",
    "                        ######################################################################\n",
    "                        result = pad_x[n, :, j*self.stride : j*self.stride+FH, \n",
    "                            i*self.stride : i*self.stride + FW] * self.W[f]\n",
    "                        out[n][f][j][i] += np.sum(result) + self.b[f]\n",
    "                        ######################################################################\n",
    "                        #                          END OF YOUR CODE                          #\n",
    "                        ######################################################################\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        \n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = self.x.shape\n",
    "        \n",
    "        out_h = self.out_h\n",
    "        out_w = self.out_w\n",
    "        \n",
    "        # padding\n",
    "        pad_x = np.pad(\n",
    "            self.x, \n",
    "            ((0, 0), (0, 0), (self.pad, self.pad), (self.pad, self.pad)), \n",
    "            \"constant\", constant_values=0\n",
    "        )\n",
    "        \n",
    "        dx = np.zeros(pad_x.shape)\n",
    "        dw = np.zeros(self.W.shape)\n",
    "        db = np.zeros(self.b.shape)\n",
    "\n",
    "        for n in range(N):\n",
    "            for f in range(FN):\n",
    "                for j in range(out_h):\n",
    "                    for i in range(out_w):\n",
    "                        ######################################################################\n",
    "                        # 문제 2-1-2 backward 구현 하세요                                    #\n",
    "                        ######################################################################\n",
    "                        dw[f] += pad_x[n, : , j* self.stride : j*self.stride + FH, \n",
    "                            i*self.stride: i*self.stride + FW] * dout[n][f][j][i]\n",
    "                        dx[n, :, j*self.stride: j*self.stride + FH, \n",
    "                            i*self.stride: i*self.stride + FW] += self.W[f] * dout[n, f, j, i]\n",
    "                db[f] = np.sum(dout[n,f,:,:])\n",
    "                        ######################################################################\n",
    "                        #                          END OF YOUR CODE                          #\n",
    "                        ######################################################################\n",
    "        # remove padding\n",
    "        dx = dx[:, :, self.pad:dx.shape[2]-self.pad, self.pad:dx.shape[3]-self.pad]\n",
    "        \n",
    "        self.db = db\n",
    "        self.dW = dw\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x[:]\n",
    "        N, C, H, W = x.shape\n",
    "        \n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "        \n",
    "        out = np.zeros((N, C, out_h, out_w))\n",
    "        for j in range(out_h):\n",
    "            for i in range(out_w):\n",
    "                ######################################################################\n",
    "                # 문제 2-2-1 forward를 구현 하세요                                   #\n",
    "                ######################################################################\n",
    "                out[:, :, j, i] = np.max(self.x[:, :, j*self.stride : j*self.stride + self.pool_h, \n",
    "                    i*self.stride : i*self.stride + self.pool_w])\n",
    "                ######################################################################\n",
    "                #                          END OF YOUR CODE                          #\n",
    "                ######################################################################\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        \n",
    "        N, C, H, W = self.x.shape\n",
    "        out_h = (H-self.pool_h) // self.stride + 1\n",
    "        out_w = (W-self.pool_w) // self.stride + 1\n",
    "\n",
    "        dx = np.zeros(self.x.shape)\n",
    "        for n in range(N):\n",
    "            for c in range(C):\n",
    "                for j in range(out_h):\n",
    "                    for i in range(out_w):\n",
    "                        ######################################################################\n",
    "                        # 문제 2-2-2 backward를 구현 하세요                                  #\n",
    "                        ######################################################################   \n",
    "                        arr = self.x[n, c, j*self.stride: j*self.stride + self.pool_h, \n",
    "                            i*self.stride : i*self.stride + self.pool_w]\n",
    "                        idx = np.nanargmax(arr)\n",
    "                        (a, b) = np.unravel_index(idx, arr.shape)\n",
    "                        dx[n][c][j*self.stride + a][i*self.stride + b] = dout[n][c][j][i]\n",
    "                        ######################################################################\n",
    "                        #                          END OF YOUR CODE                          #\n",
    "                        ######################################################################\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T06:55:19.163192Z",
     "start_time": "2020-06-07T06:55:19.146865Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleConvNet:\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        weight_init_std = 0.01\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        \n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        \n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "        \n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Conv(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = MaxPooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['FClayer1'] = FClayer(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['FClayer2'] = FClayer(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = Softmax_CE()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        ######################################################################\n",
    "        #  2-3 해당 주어진 gradient 함수에 주석을 다세요                     #\n",
    "        ######################################################################\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # loss 함수에서 predict 함수를 호출한다.\n",
    "        # predict 함수 내에서 각 layer의 foward을 순서대로 진행하여\n",
    "        # 하나의 forward prop이 끝난 에측값을 loss 함수에 return 한다.\n",
    "        # loss 함수는 softmax_CE의 forward 함수를 호출하여 loss를 계산한다. \n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "        # softmax_CE의 backward 함수를 호출하여\n",
    "        # 전파하는 값을 배치의 수로 나눈 결과, 즉 데이터 1개당 오차를 return 받는다.\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        # forward prop과 반대 방향으로 backward prop을 진행해야 하기 때문에 \n",
    "        # layers의 순서를 뒤집는다.\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "        # 각 layer의 backward를 진행하여 dout을 갱신한다.\n",
    "        # back propagation은 끝에서부터 미분값을 곱해나가는 구조이기 때문에\n",
    "        # 다음 layer의 input으로 그 전 layer의 output인 dout을 다시 넣어주는 recursive한 형태이다.\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['FClayer1'].dW, self.layers['FClayer1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['FClayer2'].dW, self.layers['FClayer2'].db\n",
    "        # 각 layer의 gradient값을 grads 객체 안에 저장하여 갱신할 매개변수들을 return 한다.\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T06:55:20.334140Z",
     "start_time": "2020-06-07T06:55:20.301677Z"
    }
   },
   "outputs": [],
   "source": [
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 3, 'filter_size': 3, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=16, output_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_show(filters, nx=8, margin=3, scale=10):\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(FN):\n",
    "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습이 되기전 conv layer 의 파라미터값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_show(network.params['W1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "train_size = x_train.shape[0]\n",
    "batch_size = 100   # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "\n",
    "test_acc_list = []\n",
    "epochs = 3\n",
    "step = int(train_size / batch_size)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx in range(step):\n",
    "        x_batch = x_train[batch_idx*batch_size:batch_idx*batch_size+batch_size]\n",
    "        y_batch = y_train[batch_idx*batch_size:batch_idx*batch_size+batch_size]\n",
    "        grad = network.gradient(x_batch, y_batch)\n",
    "\n",
    "\n",
    "        # 매개변수 갱신\n",
    "        for key in network.params.keys():\n",
    "            network.params[key] -= learning_rate * grad[key]\n",
    "\n",
    "        # 학습 경과 기록\n",
    "        loss = network.loss(x_batch, y_batch)\n",
    "        print(loss)\n",
    "    test_acc = network.accuracy(x_test, y_test)\n",
    "    test_acc_list.append(test_acc)\n",
    "    print(\" test acc | \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 후 파라미터 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "#  2-4 학습된 필터를 캡처하여 제출하세요                             #\n",
    "######################################################################\n",
    "filter_show(network.params['W1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}